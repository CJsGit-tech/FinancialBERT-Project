{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b51db5d7-56c4-436b-a29e-619ec024c67b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f648d551-a9cb-4ede-a6b6-92f2ff67a775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from datasets import load_dataset\n",
    "from transformers import (AutoModel, AutoConfig, AutoTokenizer,AutoModelForSequenceClassification,\n",
    "                          pipeline, Trainer, TrainingArguments,EarlyStoppingCallback)\n",
    "from utils.text_processing import (get_summarizer, perform_summarizer, text_filter, \n",
    "                                   get_sentiment_model, get_topic_model,compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25ffbee-c7b5-4014-a4fb-b7636c6152ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/raw_text_data.csv')\n",
    "df = text_filter(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9a2dbf-9c93-4d26-8bac-6a1cac85bb91",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Summary Generation with bert-extractive-summarizer\n",
    "- [Bert-Extractive-Summarizer](https://github.com/dmmiller612/bert-extractive-summarizer)\n",
    "- [Bart-Large-CNN](https://huggingface.co/facebook/bart-large-cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78b9356-8ca4-4112-b342-f7955a04aaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate model\n",
    "summary_model_name = 'facebook/bart-large-cnn' # pretrained model hosted on HuggingFace\n",
    "summary_model = get_summarizer(summary_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ee0c6d-2d25-4a8e-b895-aa9c786abf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perfom Summarizer\n",
    "summarized_texts = []\n",
    "sum_flag = 250\n",
    "shrink_ratio = 0.8\n",
    "\n",
    "for idx in tqdm(range(len(df)), desc='Raw Texts'):\n",
    "    text_tok_cnts = df['cnt_len'][idx]\n",
    "    raw_text = df['text'][idx]\n",
    "    \n",
    "    # When the raw text is long enough for generating a summary\n",
    "    if text_tok_cnts >= sum_flag:\n",
    "        summary = perform_summarizer(raw_text, summary_model, ratio = shrink_ratio, return_embeddings=False)\n",
    "        summary_tok_cnts = len(summary.split())\n",
    "        \n",
    "        while summary_tok_cnts >= sum_flag:\n",
    "            summary = perform_summarizer(summary, summary_model, ratio = shrink_ratio, return_embeddings=False)\n",
    "            summary_tok_cnts = len(summary.split())\n",
    "        \n",
    "        summarized_texts.append(summary)\n",
    "    \n",
    "    else:\n",
    "        summarized_texts.append(raw_text)\n",
    "        \n",
    "df['summary'] = summarized_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c040759b-c2ca-425e-a793-9122a803f5f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sentiment Label and Topic Label Generation\n",
    "- [(Used in the project) Sentiment Model 1: mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis](https://huggingface.co/mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis)\n",
    "- [Sentiment Model 2:Jean-Baptiste/roberta-large-financial-news-sentiment-en](https://huggingface.co/Jean-Baptiste/roberta-large-financial-news-sentiment-en)\n",
    "- [Topic Model: jonaskoenig/topic_classification_04](https://huggingface.co/jonaskoenig/topic_classification_04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc1ede1-d799-404e-b7e4-7740cddfa14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Financial\n",
    "financial_tokenizer, financial_model = get_sentiment_model('mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis')\n",
    "# financial_tokenizer, financial_model = get_model('Jean-Baptiste/roberta-large-financial-news-sentiment-en')\n",
    "topic_tokenizer, topic_model = get_topic_model('jonaskoenig/topic_classification_04',from_tf=True)\n",
    "\n",
    "article_tokenizer_kwargs = {'padding':'max_length',\n",
    "                            'truncation':True,\n",
    "                            'max_length':250,\n",
    "                            'add_special_tokens':True}\n",
    "\n",
    "article_classifier = pipeline(\"sentiment-analysis\", \n",
    "                              model=financial_model, \n",
    "                              tokenizer=financial_tokenizer,\n",
    "                              **article_tokenizer_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d781f4a-3a3d-44b0-87be-d17a773fae4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Sentiment Labels\n",
    "sentiment_labels = []\n",
    "sentiment_threshold = 0.7\n",
    "\n",
    "for text in tqdm(df['text'].values,total=len(df),desc='Sentiment Label Generation'):\n",
    "    \n",
    "    # Make Predictions\n",
    "    prediction = article_classifier(text)[0]\n",
    "    sentiment_label = prediction['label']\n",
    "    sentiment_score = prediction['score']\n",
    "    \n",
    "    if (sentiment_score >= sentiment_threshold) & (sentiment_label != 'neutral'):\n",
    "        sentiment_labels.append(sentiment_label)\n",
    "\n",
    "    else:\n",
    "        sentiment_labels.append('NA')\n",
    "        \n",
    "df['sentiment'] = sentiment_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9424614c-3d73-4cba-8b65-b212d3876f1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Topic Labels\n",
    "topics = []\n",
    "topic_confidence_threshold = 0.9\n",
    "\n",
    "for summary in tqdm(df.summary,total=len(df),desc='Sentiment Label Generation'):\n",
    "    \n",
    "    topic_classifier = pipeline(\"sentiment-analysis\", \n",
    "                                model=topic_model, \n",
    "                                tokenizer=topic_tokenizer,\n",
    "                                **article_tokenizer_kwargs)\n",
    "    \n",
    "    prediction = topic_classifier(text)[0]\n",
    "    topic_label = prediction['label']\n",
    "    topic_score = prediction['score']\n",
    "\n",
    "    if topic_score >= topic_confidence_threshold:\n",
    "        topics.append(topic_label)\n",
    "\n",
    "    else:\n",
    "        topics.append('NA')\n",
    "        \n",
    "df['topic'] = topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a96482-f3af-40ef-a845-68821d14f6fe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b50d5d-afab-44ff-bf47-d76b194e2c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Save to CSV ####\n",
    "# df.to_csv('data_sample.csv',index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b61b9d-a5d8-491c-b0c8-20040d67f388",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## BERT Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e8bb9c-adb9-4c35-9667-f246de7f57d4",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec3afb1-131f-4a0d-b879-5f0fd9d6ecfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_labels_cnvt(batch):\n",
    "    dicts = {'negative':0,'positive':1}\n",
    "    labels = [dicts[lbl] for lbl in batch['sentiment']]\n",
    "    return {'labels':labels}\n",
    "\n",
    "def tokenize(batch):\n",
    "    tokens = tokenizer(batch['text'], padding='max_length', max_length = 250, truncation=True)\n",
    "    return tokens\n",
    "\n",
    "def data_encoder(root, train_file, valid_file):\n",
    "\n",
    "    # Create Datasets\n",
    "    dataset = load_dataset(path = root,\n",
    "                            data_files={'train': train_file, 'valid': valid_file})\n",
    "    dataset = dataset.map(num_labels_cnvt, batched=True)\n",
    "    \n",
    "    dataset_encoded = dataset.map(tokenize,batched=True)\n",
    "    dataset_encoded.set_format(type='torch',columns=[\"input_ids\",\"attention_mask\",\"labels\"])\n",
    "    return dataset_encoded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e7d383-dae5-4a64-9073-fdfd6cbc8f33",
   "metadata": {},
   "source": [
    "#### Encoding Data and Preparing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dee7b46-3f45-4ddf-84cf-064d81685af0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Label Maps\n",
    "num_labels = 2\n",
    "id2label = {0:'Negative',1:'Postive'}\n",
    "label2id = {'Negative':0,'Positive':1}\n",
    "\n",
    "# Loading Models\n",
    "device = 'cpu'\n",
    "model_ckpt = 'distilbert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_ckpt,\n",
    "                                                                num_labels=num_labels,\n",
    "                                                                label2id=label2id,\n",
    "                                                                id2label=id2label).to(device)\n",
    "\n",
    "# Data Path\n",
    "root = 'sample_data/'\n",
    "train = 'sample_train_fold.csv'\n",
    "valid = 'sample_valid_fold.csv'\n",
    "\n",
    "encoded_dataset = data_encoder(root,train,valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92be0617-1f81-4094-ad5f-c01018af06d6",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea85a20-15db-4793-b3e2-c71b3d5ac53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "logging_steps = len(encoded_dataset['train']) // batch_size\n",
    "model_output_path = f\"saved_model/\"\n",
    "\n",
    "training_args = TrainingArguments(output_dir=model_output_path,\n",
    "                                  num_train_epochs=15,\n",
    "                                  learning_rate=2e-6,\n",
    "                                  per_device_train_batch_size=batch_size,\n",
    "                                  per_device_eval_batch_size=batch_size,\n",
    "                                  weight_decay=0.0001,\n",
    "                                  \n",
    "                                  #### EarlyStopping\n",
    "                                  evaluation_strategy = 'epoch',\n",
    "                                  save_strategy='epoch',\n",
    "                                  load_best_model_at_end = True,\n",
    "                                  metric_for_best_model = 'f1',\n",
    "                                  ##########\n",
    "                                  \n",
    "                                  disable_tqdm=False,\n",
    "                                  logging_steps=logging_steps,\n",
    "                                  push_to_hub=False,\n",
    "                                  no_cuda=False,\n",
    "                                  log_level=\"error\",\n",
    "                                  # optim = 'sgd'\n",
    "                                 )\n",
    "\n",
    "trainer = Trainer(model=model, \n",
    "                  tokenizer=tokenizer,\n",
    "                  args=training_args,\n",
    "                  compute_metrics=compute_metrics,\n",
    "                  train_dataset=encoded_dataset['train'],\n",
    "                  eval_dataset=encoded_dataset['valid'],\n",
    "                  callbacks = [EarlyStoppingCallback(early_stopping_patience=2)]\n",
    "                 )\n",
    "\n",
    "results = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a14a65e-2424-4207-81ad-44e476ab152d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
