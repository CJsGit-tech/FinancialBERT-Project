{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ShCagxFf6Xd0"
   },
   "source": [
    "## Install/ Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PwArQkAIsy4O"
   },
   "outputs": [],
   "source": [
    "! pip install -U spacy\n",
    "! python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H5El8nX2r8jk"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import re\n",
    "from scipy.sparse import csr_matrix \n",
    "\n",
    "import spacy\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "import pickle\n",
    "\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59addqYftrr6"
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWPI2zx28tz9"
   },
   "source": [
    "### tokenize & clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3MiX7phD8z4i"
   },
   "outputs": [],
   "source": [
    "def tokenization_clean(text: 'str', nlp_model: 'spacy_model'):\n",
    "  doc = nlp_model(text)\n",
    "  tok_aft_spacy = [re.sub(r'[^\\w\\s]', '', tok.lemma_.lower()) for tok in doc \n",
    "                   if not tok.is_stop\n",
    "                   and not tok.is_punct \n",
    "                   and not tok.like_num \n",
    "                   and not tok.like_url \n",
    "                   and not tok.is_space \n",
    "                   and not tok.like_email \n",
    "                   and not tok.is_left_punct \n",
    "                   and not tok.is_right_punct \n",
    "                   and not tok.is_digit \n",
    "                   and not tok.is_currency]\n",
    "  \n",
    "  join_tok_aft_spacy = ' '.join(tok_aft_spacy)\n",
    "  return join_tok_aft_spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMUZcpjm83RU"
   },
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t5nXLRtY8-CF"
   },
   "outputs": [],
   "source": [
    "def load_fold_dataset(directory: 'str', \n",
    "                      file_name: 'str', \n",
    "                      fn_tokenization_clean: 'function', \n",
    "                      nlp_model):\n",
    "  \n",
    "  tqdm.pandas()\n",
    "  path = Path(directory)\n",
    "  file_path = path / file_name\n",
    "  data = pd.read_csv(file_path)\n",
    "  data['tokenized_text'] = data['text'].progress_apply(lambda x: fn_tokenization_clean(x, nlp_model))\n",
    "  data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "  y = data[['sentiment']].copy()\n",
    "  return data, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7B3lCKlW629r"
   },
   "outputs": [],
   "source": [
    "def load_dataset(directory: 'str', file_name: 'str', fn_tokenization_clean: 'function', \n",
    "                 nlp_model, training_data = True):\n",
    "  \n",
    "  tqdm.pandas()\n",
    "  path = Path(directory)\n",
    "  file_path = path / file_name\n",
    "  data = pd.read_csv(file_path)\n",
    "\n",
    "  data['tokenized_text'] = data['text'].progress_apply(lambda x: fn_tokenization_clean(x, nlp_model))\n",
    "\n",
    "  if training_data == True:\n",
    "    X_train = data.loc[(data['timestamp']<='2018-12-31'), ['timestamp', 'text', 'tokenized_text']].copy()\n",
    "    X_valid = data.loc[(data['timestamp']>='2019-01-01') & (data['timestamp']<='2019-12-31'), ['timestamp', 'text', 'tokenized_text']].copy()\n",
    "    y_train = data.loc[(data['timestamp']<='2018-12-31'), ['timestamp', 'topics', 'sentiment']].copy()\n",
    "    y_valid = data.loc[(data['timestamp']>='2019-01-01') & (data['timestamp']<='2019-12-31'), ['timestamp', 'topics', 'sentiment']].copy()\n",
    "\n",
    "    y_train = y_train.loc[:,['timestamp', 'sentiment']].copy()\n",
    "    y_train['sentiment'] = y_train['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
    "    y_valid = y_valid.loc[:,['timestamp', 'sentiment']].copy()\n",
    "    y_valid['sentiment'] = y_valid['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
    "    return X_train, X_valid, y_train, y_valid\n",
    "  \n",
    "  elif training_data == False:\n",
    "    X = data.loc[:, ['timestamp', 'text', 'tokenized_text']].copy()\n",
    "    y = data.loc[:, ['timestamp', 'sentiment']].copy()\n",
    "    y['sentiment'] = y['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFZ5uI3P-kVn"
   },
   "source": [
    "### function to prepare 10 fold datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IxZtgRoc-oKN"
   },
   "outputs": [],
   "source": [
    "def prepare_folds_dataset(cv_path: 'str'):\n",
    "  cv_path = Path(cv_path)\n",
    "  fold_dataset = {'fold-1':{'train':None, 'valid':None}, \n",
    "                  'fold-2':{'train':None, 'valid':None}, \n",
    "                  'fold-3':{'train':None, 'valid':None}, \n",
    "                  'fold-4':{'train':None, 'valid':None}, \n",
    "                  'fold-5':{'train':None, 'valid':None}, \n",
    "                  'fold-6':{'train':None, 'valid':None}, \n",
    "                  'fold-7':{'train':None, 'valid':None}, \n",
    "                  'fold-8':{'train':None, 'valid':None}, \n",
    "                  'fold-9':{'train':None, 'valid':None}, \n",
    "                  'fold-10':{'train':None, 'valid':None}}\n",
    "\n",
    "  for i in cv_path.iterdir():\n",
    "    i.name\n",
    "    for j in i.iterdir():\n",
    "      if 'train' in j.name:\n",
    "        train_path = j\n",
    "\n",
    "        X_fold_train, y_fold_train = load_fold_dataset(directory = i, \n",
    "                                            file_name = train_path.name,\n",
    "                                            fn_tokenization_clean = tokenization_clean,\n",
    "                                            nlp_model = nlp_model)\n",
    "        \n",
    "        fold_dataset[i.name]['train'] = (X_fold_train, y_fold_train)\n",
    "      elif 'valid' in j.name:\n",
    "        valid_path = j\n",
    "\n",
    "        X_fold_valid, y_fold_valid = load_fold_dataset(directory = i,\n",
    "                                            file_name = valid_path.name,\n",
    "                                            fn_tokenization_clean = tokenization_clean,\n",
    "                                            nlp_model = nlp_model)\n",
    "        \n",
    "        fold_dataset[i.name]['valid'] = (X_fold_valid, y_fold_valid)\n",
    "  \n",
    "  return fold_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p_FqqPEU9PxM"
   },
   "source": [
    "### load loughran_mcdonal sentiment dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MfQORc9JtrPo"
   },
   "outputs": [],
   "source": [
    "def loughran_mcdonald_dict(directory: 'str', file_name: 'str'):\n",
    "  path = Path(directory)\n",
    "  file_path = path / file_name\n",
    "  data = pd.read_csv(file_path)\n",
    "\n",
    "  data_part = data[['Word', 'Negative', 'Positive', \n",
    "                    'Uncertainty', 'Litigious', 'Strong_Modal', \n",
    "                    'Weak_Modal', 'Constraining']].copy()\n",
    "\n",
    "  data_part['Word'] = data_part['Word'].str.lower()\n",
    "\n",
    "  for i in list(data_part.columns)[1:]:\n",
    "    data_part[i] = data_part[i].apply(lambda x: 1 if x >0 else 0)\n",
    "  \n",
    "  data_part.drop(index = 50741, inplace = True) # drop nan values\n",
    "  data_part.reset_index(drop = True, inplace = True)\n",
    "\n",
    "  return data_part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5V85nS809Yeo"
   },
   "source": [
    "### multiplication of doc-term maxtrix and term-sentiment matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Il-mv9769yQ1"
   },
   "outputs": [],
   "source": [
    "def combine_count_sent(data, \n",
    "                       loughran_mcdonald_dict_fn = loughran_mcdonald_dict, \n",
    "                       directory = '../data/TF-IDF Models', \n",
    "                       file_name = 'Loughran-McDonald_MasterDictionary_1993-2021.csv'):\n",
    "  \n",
    "  sent_dict = loughran_mcdonald_dict_fn(directory, file_name)\n",
    "  sparse_sent_dict = csr_matrix(sent_dict.iloc[:,1:].values)\n",
    "  news_sentiment = (data*sparse_sent_dict)\n",
    "\n",
    "  return news_sentiment.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZLoun1I9K2tO"
   },
   "source": [
    "### function of 10 fold gridsearchcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_BoYi2fnK7xB"
   },
   "outputs": [],
   "source": [
    "def gridsearchcv(folds_data: 'dict', parametergrid: 'list', model: 'function'):\n",
    "  folds = ['fold-1', 'fold-2', 'fold-3', 'fold-4', 'fold-5', 'fold-6', 'fold-7', 'fold-8', 'fold-9', 'fold-10']\n",
    "  score_dict = {'parameter': [], 'fold':[], 'train_accuracy':[], 'train_f1':[], 'valid_accuracy': [], 'valid_f1': []}\n",
    "\n",
    "  for parameter in tqdm(parametergrid):\n",
    "    model_initialized = model.set_params(preprocessing__tfidf__tfidf_vectorizer__max_features = parameter['preprocessing__tfidf__tfidf_vectorizer__max_features'], \n",
    "                                         classification__C = parameter['classification__C'], \n",
    "                                         classification__penalty = parameter['classification__penalty'])\n",
    "    \n",
    "    for fold in folds:\n",
    "      score_dict['parameter'].append(parameter)\n",
    "      X_train, y_train = folds_data[fold]['train']\n",
    "      X_valid, y_valid = folds_data[fold]['valid']\n",
    "      y_train_encoded = y_train['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
    "      y_valid_encoded = y_valid['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
    "\n",
    "      model_initialized.fit(X_train, y_train_encoded.values)\n",
    "      train_acc = model_initialized.score(X_train, y_train_encoded.values)\n",
    "      predicted_y_train = model_initialized.predict(X_train)\n",
    "      train_f1 = f1_score(y_train_encoded.values, predicted_y_train, average = 'macro')\n",
    "      valid_acc = model_initialized.score(X_valid, y_valid_encoded.values)\n",
    "      predicted_y_valid = model_initialized.predict(X_valid)\n",
    "      valid_f1 = f1_score(y_valid_encoded.values, predicted_y_valid, average = 'macro')\n",
    "\n",
    "      score_dict['fold'].append(fold)\n",
    "      score_dict['train_accuracy'].append(train_acc)\n",
    "      score_dict['train_f1'].append(train_f1)\n",
    "      score_dict['valid_accuracy'].append(valid_acc)\n",
    "      score_dict['valid_f1'].append(valid_f1)\n",
    "      \n",
    "  \n",
    "  return score_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rdvT2iW_2uo8"
   },
   "source": [
    "### function to visualize gridsearchcv scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ME7nYySu2tk1"
   },
   "outputs": [],
   "source": [
    "def visualize_gridsearchcv(cv_result: 'sklearn gridsearch model', binary = True):\n",
    "  color = ['#AED6F1', '#5DADE2', '#2E86C1', '#21618C', '#1B2631']\n",
    "  features_list = [2000, 4000, 6000, 8000, 10000]\n",
    "\n",
    "  if binary != True:\n",
    "\n",
    "    df_cv_result = pd.DataFrame(cv_result)\n",
    "    df_cv_result = df_cv_result[['classification__estimator__C', \n",
    "                                'preprocessing__tfidf__tfidf_vectorizer__max_features', \n",
    "                                'valid_f1']].copy()\n",
    "                                \n",
    "    df_cv_result.rename(columns = {'classification__estimator__C': 'linearSVC_C', \n",
    "                                  'preprocessing__tfidf__tfidf_vectorizer__max_features': 'tfidf_feature'}, \n",
    "                        inplace = True)\n",
    "  elif binary == True:\n",
    "\n",
    "    df_cv_result = pd.DataFrame(cv_result)\n",
    "    df_cv_result = df_cv_result[['classification__C', \n",
    "                                'preprocessing__tfidf__tfidf_vectorizer__max_features', \n",
    "                                'valid_f1']].copy()\n",
    "                                \n",
    "    df_cv_result.rename(columns = {'classification__C': 'linearSVC_C', \n",
    "                                  'preprocessing__tfidf__tfidf_vectorizer__max_features': 'tfidf_feature'}, \n",
    "                        inplace = True)\n",
    "  \n",
    "  fig, ax = plt.subplots(5, 1, figsize = (11, 7))\n",
    "  for idx, feature_no, color in zip(range(len(features_list)), features_list, color):\n",
    "    ax[idx].plot(df_cv_result.loc[(df_cv_result['tfidf_feature'] == feature_no), 'linearSVC_C'], \n",
    "                 df_cv_result.loc[(df_cv_result['tfidf_feature'] == feature_no), ('valid_f1', 'mean')],\n",
    "                 color = color,\n",
    "                 linewidth = 0.5, \n",
    "                 label = f'tfidf_feature number: {feature_no}')\n",
    "    \n",
    "    ax[idx].errorbar(df_cv_result.loc[(df_cv_result['tfidf_feature'] == feature_no), 'linearSVC_C'], \n",
    "                     df_cv_result.loc[(df_cv_result['tfidf_feature'] == feature_no), ('valid_f1', 'mean')],\n",
    "                     df_cv_result.loc[(df_cv_result['tfidf_feature'] == feature_no), ('valid_f1', 'std')], \n",
    "                     linestyle='None', \n",
    "                     marker='o', \n",
    "                     markersize=3, \n",
    "                     color = color)\n",
    "    \n",
    "    ax[idx].set_ylabel('mean valid f1', fontsize =7)\n",
    "    ax[idx].legend(fontsize = 8)\n",
    "    ax[idx].set_ylim(0.75, 0.79)\n",
    "    ax[idx].tick_params(labelsize = 8, pad = 0.8)\n",
    "    \n",
    "    for text, x, y in zip(df_cv_result.loc[(df_cv_result['tfidf_feature'] == feature_no), ('valid_f1', 'mean')], \n",
    "                          df_cv_result.loc[(df_cv_result['tfidf_feature'] == feature_no), 'linearSVC_C'], \n",
    "                          df_cv_result.loc[(df_cv_result['tfidf_feature'] == feature_no), ('valid_f1', 'mean')]):\n",
    "      ax[idx].annotate('{:.4f}'.format(text), (x+0.0005, y+0.001), fontsize = 9)\n",
    "    \n",
    "    if idx == 0:\n",
    "      ax[idx].set_title('f1 score (macro) of the grid search cv results (error bar: +/- 1 std)')\n",
    "    \n",
    "    \n",
    "\n",
    "  plt.xlabel('linear SVC, C value', fontsize = 7)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "899zwDcu-OLa"
   },
   "source": [
    "### function to visualize confusion matrix (binary label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-8ShYoZu-N1s"
   },
   "outputs": [],
   "source": [
    "def performance_metrics_binary(model, data, true_y, train_valid: 'str'):\n",
    "  predicted_y = model.predict(data)\n",
    "  accuracy_score = model.score(data, true_y)\n",
    "  f1score = f1_score(true_y, predicted_y, average = 'macro')\n",
    "  \n",
    "\n",
    "  plt.figure(figsize = (4, 4))\n",
    "  sns.set(font_scale=1.2)\n",
    "  cm_result = confusion_matrix(true_y, predicted_y, normalize = 'true')\n",
    "\n",
    "  confusion_matrix_result_heatmap = sns.heatmap(cm_result, \n",
    "                                                cmap=\"Blues\", \n",
    "                                                annot = True, \n",
    "                                                fmt=\".2f\", annot_kws={'size': 15}, \n",
    "                                                xticklabels=['Negative', 'Positive'], \n",
    "                                                yticklabels=['Negative', 'Positive'])\n",
    "\n",
    "  confusion_matrix_result_heatmap.set(xlabel='Predicted Label', ylabel='True Label', title = 'sentiment')\n",
    "\n",
    "  plt.show()\n",
    "  print(f'\\n{train_valid} accuracy: {accuracy_score}, {train_valid} f1 score: {f1score}')\n",
    "  return accuracy_score, f1score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0_yDJy6R44J"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CmEnwmRp_rIm"
   },
   "source": [
    "### initialize spacy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ME8CJNjDtVRq"
   },
   "outputs": [],
   "source": [
    "nlp_model = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4PSnxwQUASvn"
   },
   "source": [
    "### prepare loughran-mcdonald sentiment dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dDnU5ckbAX5f"
   },
   "outputs": [],
   "source": [
    "lm_sent_dict = loughran_mcdonald_dict(directory = '../data/TF-IDF Models', \n",
    "                                      file_name = 'Loughran-McDonald_MasterDictionary_1993-2021.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cOOXMM1iLGEU"
   },
   "source": [
    "### prepare 10 folds of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Q_-jHfGLLBc"
   },
   "outputs": [],
   "source": [
    "folds_data_path = Path(r'../data/TF-IDF Models/Intermediate Output/dict_folds_data_text_only.pickle')\n",
    "\n",
    "if folds_data_path.is_file():\n",
    "  with open(folds_data_path, 'rb') as f_1:\n",
    "    dict_folds_data = pickle.load(f_1)\n",
    "\n",
    "else:\n",
    "  dict_folds_data = prepare_folds_dataset(cv_path = r'../data/TF-IDF Models/Cross Validation_fold_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VccwazMzRHDj"
   },
   "source": [
    "## Binary Label Classifier & Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "djmOu2a6BDWm"
   },
   "source": [
    "### initialize necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FLugrZA572n1"
   },
   "outputs": [],
   "source": [
    "lm_countvectorizer = CountVectorizer(vocabulary = lm_sent_dict ['Word'])\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range = (1, 2), max_features = 10000)\n",
    "minmaxscaler = MinMaxScaler()\n",
    "fn_combine = FunctionTransformer(combine_count_sent)\n",
    "fn_transform_sparse = FunctionTransformer(csr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ij19E1mPVCiy"
   },
   "source": [
    "### build pipeline (binary label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "05mtNKsqQXrc"
   },
   "outputs": [],
   "source": [
    "tfidf_pipline = Pipeline(steps = [('tfidf_vectorizer', tfidf_vectorizer)])\n",
    "\n",
    "lm_pipeline = Pipeline(steps = [('count_vectorizer', lm_countvectorizer), \n",
    "                                ('matrix_mul', fn_combine), \n",
    "                                ('norm', minmaxscaler), \n",
    "                                ('sparse_matrix', fn_transform_sparse)])\n",
    "\n",
    "column_transformer = ColumnTransformer(transformers = [('tfidf', tfidf_pipline, 'tokenized_text'),\n",
    "                                                       ('lm_count', lm_pipeline, 'tokenized_text')])\n",
    "\n",
    "clf_pipeline_binary = Pipeline(steps = [('preprocessing', column_transformer), \n",
    "                                        ('classification',LinearSVC(C= 0.9, class_weight = 'balanced'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4z5Lk9RBR_P"
   },
   "source": [
    "### prepare X and y (binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "axjkb_LRVH8y"
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = load_dataset(directory = '../data/TF-IDF Models/News Article Text File',\n",
    "                                                  file_name = 'articles_2015_2019.csv', \n",
    "                                                  fn_tokenization_clean = tokenization_clean, \n",
    "                                                  nlp_model = nlp_model, \n",
    "                                                  training_data = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PbcPn6uTRoKW"
   },
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OM87jIhTEluQ"
   },
   "outputs": [],
   "source": [
    "parameters_grid = {'preprocessing__tfidf__tfidf_vectorizer__max_features':[2000, 4000, 6000, 8000, 10000],\n",
    "                   'classification__C': [0.1, 0.3, 0.5, 0.7, 0.9, 1.1, 1.2, 1.3], \n",
    "                   'classification__penalty': ['l2']}\n",
    "\n",
    "grid = ParameterGrid(parameters_grid)\n",
    "\n",
    "grid_score_dict = gridsearchcv(folds_data = dict_folds_data, \n",
    "                               parametergrid = grid, \n",
    "                               model = clf_pipeline_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VhorsffadOMp"
   },
   "outputs": [],
   "source": [
    "parameters_grid_1 = {'preprocessing__tfidf__tfidf_vectorizer__max_features':[],\n",
    "                   'classification__C': [], \n",
    "                   'classification__penalty': []}\n",
    "\n",
    "df_result_binary = pd.DataFrame(grid_score_dict)\n",
    "\n",
    "for parameter in df_result_binary['parameter']:\n",
    "  for key, value in parameter.items():\n",
    "    parameters_grid_1[key].append(value)\n",
    "\n",
    "df_result_binary_1 = df_result_binary.merge(pd.DataFrame(parameters_grid_1), how = 'left', left_index = True, right_index = True)\n",
    "df_result_binary_complete = df_result_binary_1.iloc[:,1:].groupby(['preprocessing__tfidf__tfidf_vectorizer__max_features',\n",
    "                                                                   'classification__C',\n",
    "                                                                   'classification__penalty'], as_index = False).agg({'train_accuracy':['mean', 'std'], 'train_f1':['mean', 'std'], 'valid_accuracy': ['mean', 'std'], 'valid_f1': ['mean', 'std']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "25rrhYwZUN-x"
   },
   "outputs": [],
   "source": [
    "df_result_binary_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jMCNd2-42Y5u"
   },
   "outputs": [],
   "source": [
    "visualize_gridsearchcv(df_result_binary_complete, binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HVKE-H26Oe4s"
   },
   "outputs": [],
   "source": [
    "df_result_binary_complete.iloc[df_result_binary_complete[('valid_f1', 'mean')].idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F6JkSIGA4W-Q"
   },
   "source": [
    "### initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TxDZ5sGM4Wgo"
   },
   "outputs": [],
   "source": [
    "lm_countvectorizer = CountVectorizer(vocabulary = lm_sent_dict ['Word'])\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range = (1, 2), max_features = 10000)\n",
    "minmaxscaler = MinMaxScaler()\n",
    "fn_combine = FunctionTransformer(combine_count_sent)\n",
    "fn_transform_sparse = FunctionTransformer(csr_matrix)\n",
    "\n",
    "tfidf_pipline = Pipeline(steps = [('tfidf_vectorizer', tfidf_vectorizer)])\n",
    "\n",
    "lm_pipeline = Pipeline(steps = [('count_vectorizer', lm_countvectorizer), \n",
    "                                ('matrix_mul', fn_combine), \n",
    "                                ('norm', minmaxscaler), \n",
    "                                ('sparse_matrix', fn_transform_sparse)])\n",
    "\n",
    "column_transformer = ColumnTransformer(transformers = [('tfidf', tfidf_pipline, 'tokenized_text'),\n",
    "                                                       ('lm_count', lm_pipeline, 'tokenized_text')])\n",
    "\n",
    "clf_pipeline_binary = Pipeline(steps = [('preprocessing', column_transformer), \n",
    "                                        ('classification', LinearSVC(C= 0.1, class_weight = 'balanced'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "shMoNGLdACSG"
   },
   "source": [
    "### cross validation (Monte Carlo CV) / 10 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e79Q3feuEuIS"
   },
   "outputs": [],
   "source": [
    "folds = ['fold-1', 'fold-2', 'fold-3', 'fold-4', 'fold-5', 'fold-6', 'fold-7', 'fold-8', 'fold-9', 'fold-10']\n",
    "mccv_score_dict = {'fold':[], 'train_accuracy':[], 'train_f1':[], 'valid_accuracy': [], 'valid_f1': []}\n",
    "  \n",
    "for fold in tqdm(folds):\n",
    "  X_train_fold, y_train_fold = dict_folds_data[fold]['train']\n",
    "  X_valid_fold, y_valid_fold = dict_folds_data[fold]['valid']\n",
    "\n",
    "  y_train_fold_encoded = y_train_fold['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
    "  y_valid_fold_encoded = y_valid_fold['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
    "\n",
    "  clf_pipeline_binary.fit(X_train_fold, y_train_fold_encoded.values)\n",
    "  train_acc = clf_pipeline_binary.score(X_train_fold, y_train_fold_encoded.values)\n",
    "  predicted_y_train = clf_pipeline_binary.predict(X_train_fold)\n",
    "  train_f1 = f1_score(y_train_fold_encoded.values, predicted_y_train, average = 'macro')\n",
    "  valid_acc = clf_pipeline_binary.score(X_valid_fold, y_valid_fold_encoded.values)\n",
    "  predicted_y_valid = clf_pipeline_binary.predict(X_valid_fold)\n",
    "  valid_f1 = f1_score(y_valid_fold_encoded.values, predicted_y_valid, average = 'macro')\n",
    "\n",
    "  mccv_score_dict['fold'].append(fold)\n",
    "  mccv_score_dict['train_accuracy'].append(train_acc)\n",
    "  mccv_score_dict['train_f1'].append(train_f1)\n",
    "  mccv_score_dict['valid_accuracy'].append(valid_acc)\n",
    "  mccv_score_dict['valid_f1'].append(valid_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nZoKxbd-hDxA"
   },
   "outputs": [],
   "source": [
    "df_mccv_result = pd.DataFrame(mccv_score_dict)\n",
    "df_mccv_result.loc[len(df_mccv_result)] = ['average', \n",
    "                                           df_mccv_result['train_accuracy'].mean(), \n",
    "                                           df_mccv_result['train_f1'].mean(), \n",
    "                                           df_mccv_result['valid_accuracy'].mean(), \n",
    "                                           df_mccv_result['valid_f1'].mean()]\n",
    "\n",
    "df_mccv_result.loc[len(df_mccv_result)] = ['std', \n",
    "                                           df_mccv_result.iloc[:-1,1].std(), \n",
    "                                           df_mccv_result.iloc[:-1,2].std(), \n",
    "                                           df_mccv_result.iloc[:-1,3].std(), \n",
    "                                           df_mccv_result.iloc[:-1,4].std()]\n",
    "df_mccv_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0z3vVWfZY1Z0"
   },
   "source": [
    "### confirm the best model of binary label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OlmoVEHdYh5k"
   },
   "outputs": [],
   "source": [
    "lm_countvectorizer = CountVectorizer(vocabulary = lm_sent_dict ['Word'])\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range = (1, 2), max_features = 10000)\n",
    "minmaxscaler = MinMaxScaler()\n",
    "fn_combine = FunctionTransformer(combine_count_sent)\n",
    "fn_transform_sparse = FunctionTransformer(csr_matrix)\n",
    "\n",
    "tfidf_pipline = Pipeline(steps = [('tfidf_vectorizer', tfidf_vectorizer)])\n",
    "\n",
    "lm_pipeline = Pipeline(steps = [('count_vectorizer', lm_countvectorizer), \n",
    "                                ('matrix_mul', fn_combine), \n",
    "                                ('norm', minmaxscaler), \n",
    "                                ('sparse_matrix', fn_transform_sparse)])\n",
    "\n",
    "column_transformer = ColumnTransformer(transformers = [('tfidf', tfidf_pipline, 'tokenized_text'),\n",
    "                                                       ('lm_count', lm_pipeline, 'tokenized_text')])\n",
    "\n",
    "clf_pipeline_binary = Pipeline(steps = [('preprocessing', column_transformer), \n",
    "                                        ('classification', LinearSVC(C= 0.1, class_weight = 'balanced'))])\n",
    "\n",
    "clf_pipeline_binary.fit(X_train, y_train['sentiment'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wiP0tA8bPsNX"
   },
   "source": [
    "### performance evaluation & visualization (train dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7La9BIwlPr3x"
   },
   "outputs": [],
   "source": [
    "accuracy_score_train, f1score_train = performance_metrics_binary(model = clf_pipeline_binary, data = X_train, true_y = y_train['sentiment'].values, train_valid = 'train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6QpIeQwRsSd"
   },
   "source": [
    "### performance evaluation & visualization (valid dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xyXrQmpZ5LZB"
   },
   "outputs": [],
   "source": [
    "accuracy_score_valid, f1score_valid = performance_metrics_binary(model = clf_pipeline_binary, data = X_valid, true_y = y_valid['sentiment'].values, train_valid = 'valid')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
