{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","mount_file_id":"12yUbLAhr4NeBh64CvAAMK4LdzvilL8I4","authorship_tag":"ABX9TyPXVutblEXZw9/BmE349un7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium"},"cells":[{"cell_type":"markdown","source":["## Install/ Import Library"],"metadata":{"id":"HDHmsKfaPbiQ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"46rxgJm7ODch"},"outputs":[],"source":["! pip install yfinance"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","import seaborn as sns\n","import re\n","from scipy.sparse import csr_matrix\n","\n","from tqdm.auto import tqdm\n","from pathlib import Path\n","import os\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import FunctionTransformer, MinMaxScaler, OneHotEncoder\n","from sklearn.multiclass import OneVsRestClassifier\n","from sklearn.svm import LinearSVC\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n","from sklearn.model_selection import ParameterGrid\n","from sklearn.ensemble import StackingClassifier\n","from sklearn.linear_model import LogisticRegression\n","\n","from xgboost import XGBClassifier\n","\n","import yfinance\n","\n","import pickle\n"],"metadata":{"id":"xwTRkhSwPgDA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Helper Functions"],"metadata":{"id":"59addqYftrr6"}},{"cell_type":"markdown","source":["### load sp500 data & prepare technical index"],"metadata":{"id":"MXwpJQsxVQh4"}},{"cell_type":"code","source":["def load_sp500_data(start_date = '2014-12-31', end_date = '2021-01-05'):\n","  sp = yfinance.Ticker('^GSPC')\n","  sp_history = sp.history(start =start_date, end = end_date)\n","  sp_history.reset_index(inplace = True)\n","  sp_history['Date'] = pd.to_datetime(sp_history['Date'].dt.date)\n","  sp_history.drop(labels = ['Dividends', 'Stock Splits'], axis = 1, inplace = True)\n","  sp_history = sp_history.loc[:,['Date', 'Open', 'High', 'Low', 'Volume', 'Close']]\n","  sp_history['Close+1day'] = sp_history['Close'].shift(-1)\n","  sp_history.dropna(inplace = True)\n","  sp_history['up_down'] = sp_history[['Close', 'Close+1day']].apply(lambda x: 1 if x['Close+1day'] > x['Close'] else 0, axis = 1)\n","\n","  appl = yfinance.Ticker('AAPL')\n","  appl_history = appl.history(start =start_date, end = end_date)\n","  appl_history.reset_index(inplace = True)\n","  appl_history['Date'] = pd.to_datetime(appl_history['Date'].dt.date)\n","  appl_history['Close'] = appl_history['Close'].pct_change()\n","\n","  msft = yfinance.Ticker('MSFT')\n","  msft_history = msft.history(start =start_date, end = end_date)\n","  msft_history.reset_index(inplace = True)\n","  msft_history['Date'] = pd.to_datetime(msft_history['Date'].dt.date)\n","  msft_history['Close'] = msft_history['Close'].pct_change()\n","\n","  amzn = yfinance.Ticker('AMZN')\n","  amzn_history = amzn.history(start =start_date, end = end_date)\n","  amzn_history.reset_index(inplace = True)\n","  amzn_history['Date'] = pd.to_datetime(amzn_history['Date'].dt.date)\n","  amzn_history['Close'] = amzn_history['Close'].pct_change()\n","\n","  nvda = yfinance.Ticker('NVDA')\n","  nvda_history = nvda.history(start =start_date, end = end_date)\n","  nvda_history.reset_index(inplace = True)\n","  nvda_history['Date'] = pd.to_datetime(nvda_history['Date'].dt.date)\n","  nvda_history['Close'] = nvda_history['Close'].pct_change()\n","\n","  brk = yfinance.Ticker('BRK-B')\n","  brk_history = brk.history(start =start_date, end = end_date)\n","  brk_history.reset_index(inplace = True)\n","  brk_history['Date'] = pd.to_datetime(brk_history['Date'].dt.date)\n","  brk_history['Close'] = brk_history['Close'].pct_change()\n","\n","  googl = yfinance.Ticker('GOOGL')\n","  googl_history = googl.history(start =start_date, end = end_date)\n","  googl_history.reset_index(inplace = True)\n","  googl_history['Date'] = pd.to_datetime(googl_history['Date'].dt.date)\n","  googl_history['Close'] = googl_history['Close'].pct_change()\n","\n","  tsla = yfinance.Ticker('TSLA')\n","  tsla_history = tsla.history(start =start_date, end = end_date)\n","  tsla_history.reset_index(inplace = True)\n","  tsla_history['Date'] = pd.to_datetime(tsla_history['Date'].dt.date)\n","  tsla_history['Close'] = tsla_history['Close'].pct_change()\n","\n","  meta = yfinance.Ticker('META')\n","  meta_history = meta.history(start =start_date, end = end_date)\n","  meta_history.reset_index(inplace = True)\n","  meta_history['Date'] = pd.to_datetime(meta_history['Date'].dt.date)\n","  meta_history['Close'] = meta_history['Close'].pct_change()\n","\n","  xom = yfinance.Ticker('XOM')\n","  xom_history = xom.history(start =start_date, end = end_date)\n","  xom_history.reset_index(inplace = True)\n","  xom_history['Date'] = pd.to_datetime(xom_history['Date'].dt.date)\n","  xom_history['Close'] = xom_history['Close'].pct_change()\n","\n","  jpm = yfinance.Ticker('JPM')\n","  jpm_history = jpm.history(start =start_date, end = end_date)\n","  jpm_history.reset_index(inplace = True)\n","  jpm_history['Date'] = pd.to_datetime(jpm_history['Date'].dt.date)\n","  jpm_history['Close'] = jpm_history['Close'].pct_change()\n","\n","  for i in [10, 20, 30]:\n","    sp_history['MA'+str(i)] = sp_history['Close'].rolling(i).mean()\n","\n","  for df, name in zip([appl_history, msft_history, amzn_history, nvda_history, brk_history, \n","                       googl_history, tsla_history, meta_history, xom_history, jpm_history], \n","                      ['appl_Close', 'msft_Close', 'amzn_Close', 'nvda_Close', 'brk_Close', \n","                       'googl_Close', 'tsla_Cloae', 'meta_Close', 'xom_Close', 'jpm_Close']):\n","    df = df[['Date', 'Close']].rename(columns = {'Close': name})\n","    sp_history = sp_history.merge(df, left_on = 'Date', right_on = 'Date', how = 'left')\n","  \n","  sp_history = sp_history[(sp_history['Date'] >= '2014-12-31') & (sp_history['Date'] <= '2020-12-31')].copy()\n","  sp_history.dropna(inplace = True)\n","\n","  return sp_history"],"metadata":{"id":"KdZs9IMzVQh5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### load text dataset & combine sp500"],"metadata":{"id":"IMUZcpjm83RU"}},{"cell_type":"code","source":["def load_fold_dataset(directory: 'str', \n","                      file_name: 'str',\n","                      sp500_fn: 'function'):\n","  \n","  path = Path(directory)\n","  file_path = path / file_name\n","  data = pd.read_csv(file_path)\n","  start_date = data['timestamp'].unique()[0]\n","  end_date = data['timestamp'].unique()[-1]\n","  sp500 = sp500_fn()\n","\n","  column_subset_X = ['Date','Close'] + list(sp500.columns[8:])\n","\n","  data_X = sp500.loc[(sp500['Date']>= start_date) & (sp500['Date'] <= end_date),column_subset_X].copy()\n","  data_y = sp500.loc[(sp500['Date']>= start_date) & (sp500['Date'] <= end_date),['Date', 'up_down']]\n","\n","  return data_X, data_y"],"metadata":{"id":"t5nXLRtY8-CF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_dataset(sp500_fn: 'function', \n","                 training_data = True):\n","\n","  sp500 = sp500_fn()\n","\n","  column_subset_X = ['Date','Close'] + list(sp500.columns[8:])\n","\n","  data_X = sp500.loc[:,column_subset_X].copy()\n","  data_y = sp500.loc[:,['Date', 'up_down']]\n","  \n","  if training_data == True:\n","    X_train = data_X[data_X['Date']<='2018-12-31'].copy()\n","    X_valid = data_X[(data_X['Date']>='2019-01-01') & (data_X['Date']<='2019-12-31')].copy()\n","    y_train = data_y[data_y['Date']<='2018-12-31'].copy()\n","    y_valid = data_y[(data_X['Date']>='2019-01-01') & (data_X['Date']<='2019-12-31')].copy()\n","    return X_train, X_valid, y_train, y_valid\n","  \n","  elif training_data == False:\n","    X_train = data_X[data_X['Date']<='2019-12-31'].copy()\n","    X_test = data_X[(data_X['Date']>='2020-01-01')].copy()\n","    y_train = data_y[data_y['Date']<='2019-12-31'].copy()\n","    y_test = data_y[(data_X['Date']>='2020-01-01')].copy()\n","    return X_train, X_test, y_train, y_test"],"metadata":{"id":"7B3lCKlW629r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### function to prepare 10 folds data"],"metadata":{"id":"mdTo-yrj50_d"}},{"cell_type":"code","source":["def prepare_folds_dataset(cv_path: 'str'):\n","  cv_path = Path(cv_path)\n","  fold_dataset = {'fold-1':{'train':None, 'valid':None}, \n","                  'fold-2':{'train':None, 'valid':None}, \n","                  'fold-3':{'train':None, 'valid':None}, \n","                  'fold-4':{'train':None, 'valid':None}, \n","                  'fold-5':{'train':None, 'valid':None}, \n","                  'fold-6':{'train':None, 'valid':None}, \n","                  'fold-7':{'train':None, 'valid':None}, \n","                  'fold-8':{'train':None, 'valid':None}, \n","                  'fold-9':{'train':None, 'valid':None}, \n","                  'fold-10':{'train':None, 'valid':None}}\n","\n","  for i in cv_path.iterdir():\n","    i.name\n","    for j in i.iterdir():\n","      if 'train' in j.name:\n","        train_path = j\n","\n","        X_fold_train, y_fold_train = load_fold_dataset(directory = i, \n","                                            file_name = train_path.name,\n","                                            sp500_fn = load_sp500_data)\n","        fold_dataset[i.name]['train'] = (X_fold_train, y_fold_train)\n","      elif 'valid' in j.name:\n","        valid_path = j\n","\n","        X_fold_valid, y_fold_valid = load_fold_dataset(directory = i,\n","                                            file_name = valid_path.name,\n","                                            sp500_fn = load_sp500_data)\n","        fold_dataset[i.name]['valid'] = (X_fold_valid, y_fold_valid)\n","  \n","  return fold_dataset"],"metadata":{"id":"qCnfqzop57Vw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### load loughran_mcdonal sentiment dictionary"],"metadata":{"id":"p_FqqPEU9PxM"}},{"cell_type":"code","source":["def loughran_mcdonald_dict(directory: 'str', file_name: 'str'):\n","  path = Path(directory)\n","  file_path = path / file_name\n","  data = pd.read_csv(file_path)\n","\n","  data_part = data[['Word', 'Negative', 'Positive', \n","                    'Uncertainty', 'Litigious', 'Strong_Modal', \n","                    'Weak_Modal', 'Constraining']].copy()\n","\n","  data_part['Word'] = data_part['Word'].str.lower()\n","\n","  for i in list(data_part.columns)[1:]:\n","    data_part[i] = data_part[i].apply(lambda x: 1 if x >0 else 0)\n","  \n","  data_part.drop(index = 50741, inplace = True) # drop nan values\n","  data_part.reset_index(drop = True, inplace = True)\n","\n","  return data_part"],"metadata":{"id":"MfQORc9JtrPo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### gridsearchcv, using 10 folds dataset (Linear SVC)"],"metadata":{"id":"vlZ3y8Hl9GgZ"}},{"cell_type":"code","source":["def gridsearchcv(folds_data: 'dict', parametergrid: 'list', model: 'function'):\n","  folds = ['fold-1', 'fold-2', 'fold-3', 'fold-4', 'fold-5', 'fold-6', 'fold-7', 'fold-8', 'fold-9', 'fold-10']\n","  score_dict = {'parameter': [], 'fold':[], 'train_accuracy':[], 'train_f1':[], 'valid_accuracy': [], 'valid_f1': []}\n","\n","  for parameter in tqdm(parametergrid):\n","    model_initialized = model.set_params(classification__C = parameter['classification__C'], \n","                                         classification__penalty = parameter['classification__penalty'])\n","    \n","    for fold in folds:\n","      score_dict['parameter'].append(parameter)\n","      X_train, y_train = folds_data[fold]['train']\n","      X_valid, y_valid = folds_data[fold]['valid']\n","      model_initialized.fit(X_train, y_train['up_down'].values)\n","      train_acc = model_initialized.score(X_train, y_train['up_down'].values)\n","      predicted_y_train = model_initialized.predict(X_train)\n","      train_f1 = f1_score(y_train['up_down'].values, predicted_y_train, average = 'macro')\n","      valid_acc = model_initialized.score(X_valid, y_valid['up_down'].values)\n","      predicted_y_valid = model_initialized.predict(X_valid)\n","      valid_f1 = f1_score(y_valid['up_down'].values, predicted_y_valid, average = 'macro')\n","\n","      score_dict['fold'].append(fold)\n","      score_dict['train_accuracy'].append(train_acc)\n","      score_dict['train_f1'].append(train_f1)\n","      score_dict['valid_accuracy'].append(valid_acc)\n","      score_dict['valid_f1'].append(valid_f1)\n","  \n","  return score_dict\n"],"metadata":{"id":"NVDXIfSD9dvS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### function to visualize gridsearchcv scores (linearSVC)"],"metadata":{"id":"rdvT2iW_2uo8"}},{"cell_type":"code","source":["def visualize_gridsearchcv(cv_result: 'df'):\n","  plt.figure(figsize = (12, 6))\n","  plt.plot(cv_result['classification__C'], cv_result[('valid_f1', 'mean')], label = 'valid f1 macro', color = 'blue')\n","  plt.errorbar(x = cv_result['classification__C'], y = cv_result[('valid_f1', 'mean')], yerr = cv_result[('valid_f1', 'std')], label = '+/- 1 std', color = 'blue')\n","  \n","  for row in cv_result.itertuples():\n","    plt.annotate('{:.4f}'.format(row[-2]), xy = (row[1] + 0.0001, row[-2] + 0.0002), color = 'black', fontsize = 10)\n","    plt.annotate(f'std: {row[-1]:.4f}', xy = (row[1] + 0.0001, row[-2] + 0.005), color = 'red', fontsize = 10)\n","  \n","  plt.legend()\n","  plt.xlim((0, 0.055))\n","  plt.xlabel('linear SVC, C value')\n","  plt.ylabel('valid f1 score (macro)')\n","  plt.show()"],"metadata":{"id":"ME7nYySu2tk1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### gridsearchcv, using 10 folds dataset (XGBoost)"],"metadata":{"id":"zAG43EdAtAGQ"}},{"cell_type":"code","source":["def gridsearchcv_xgb(folds_data: 'dict', parametergrid: 'list', model: 'function'):\n","  folds = ['fold-1', 'fold-2', 'fold-3', 'fold-4', 'fold-5', 'fold-6', 'fold-7', 'fold-8', 'fold-9', 'fold-10']\n","  score_dict = {'parameter': [], 'fold':[], 'train_accuracy':[], 'train_f1':[], 'valid_accuracy': [], 'valid_f1': []}\n","\n","  for parameter in tqdm(parametergrid):\n","    model_initialized = model.set_params(classification__learning_rate = parameter['classification__learning_rate'], \n","                                         classification__max_depth = parameter['classification__max_depth'])\n","    \n","    for fold in folds:\n","      score_dict['parameter'].append(parameter)\n","      X_train, y_train = folds_data[fold]['train']\n","      X_valid, y_valid = folds_data[fold]['valid']\n","      model_initialized.fit(X_train, y_train['up_down'].values)\n","      train_acc = model_initialized.score(X_train, y_train['up_down'].values)\n","      predicted_y_train = model_initialized.predict(X_train)\n","      train_f1 = f1_score(y_train['up_down'].values, predicted_y_train, average = 'macro')\n","      valid_acc = model_initialized.score(X_valid, y_valid['up_down'].values)\n","      predicted_y_valid = model_initialized.predict(X_valid)\n","      valid_f1 = f1_score(y_valid['up_down'].values, predicted_y_valid, average = 'macro')\n","\n","      score_dict['fold'].append(fold)\n","      score_dict['train_accuracy'].append(train_acc)\n","      score_dict['train_f1'].append(train_f1)\n","      score_dict['valid_accuracy'].append(valid_acc)\n","      score_dict['valid_f1'].append(valid_f1)\n","  \n","  return score_dict"],"metadata":{"id":"nt1auF4dtENq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### function to visualize gridsearchcv result (XGBoost)"],"metadata":{"id":"jEQ1Xyt6c-89"}},{"cell_type":"code","source":["def visualize_gridsearchcv_xgb(cv_result: 'df'):\n","  depth_list = [3, 4, 5]  \n","  df_cv_result = cv_result[['classification__learning_rate',\n","                            'classification__max_depth',\n","                            'valid_f1']].copy()\n","                               \n","  df_cv_result.rename(columns = {'classification__learning_rate': 'learning_rate', \n","                                 'classification__max_depth': 'max_depth'}, \n","                      inplace = True)\n","\n","  plt.figure(figsize = (8, 6))\n","\n","  for idx, depth_no in zip(range(len(depth_list)), depth_list):\n","    ax = plt.subplot(3, 1, idx+1)\n","    ax.plot(df_cv_result.loc[(df_cv_result['max_depth'] == depth_no), 'learning_rate'], \n","            df_cv_result.loc[(df_cv_result['max_depth'] == depth_no), ('valid_f1', 'mean')].values,\n","            color = 'blue', \n","            linewidth = 1, \n","            label = f'depth: {depth_no}')\n","    ax.errorbar(x = df_cv_result.loc[(df_cv_result['max_depth'] == depth_no), 'learning_rate'],\n","                y = df_cv_result.loc[(df_cv_result['max_depth'] == depth_no), ('valid_f1', 'mean')].values, \n","                yerr = df_cv_result.loc[(df_cv_result['max_depth'] == depth_no), ('valid_f1', 'std')].values, \n","                label = '+/- 1 std', color = 'blue')\n","    \n","    for row in df_cv_result.loc[(df_cv_result['max_depth'] == depth_no),:].itertuples():\n","      ax.annotate(f'{row[-2]:.4f}', (row[1], row[-2] + 0.001), fontsize = 10)\n","      ax.annotate(f'{row[-1]:.4f}', (row[1], row[-1] + 0.004), fontsize = 10)\n","\n","    \n","    ax.set_ylim((0.3, 0.6))\n","    ax.set_ylabel('mean f1', fontsize = 12)\n","    plt.yticks(fontsize=9)\n","    ax.legend(fontsize = 10)\n","\n","    if idx != len(depth_list) - 1:\n","      ax.tick_params(labelbottom=False)\n","    \n","    if idx == 0:\n","      plt.title('validation f1 macro of the grid search cv results')\n","    \n","  plt.tight_layout(pad = 0.5)\n","  plt.xlabel('XGBoost, learning rate', fontsize = 12)\n","  plt.show()"],"metadata":{"id":"Ovbq8GIjdHg9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### function to visualize confusion matrix (binary label)"],"metadata":{"id":"899zwDcu-OLa"}},{"cell_type":"code","source":["def performance_metrics_binary(model, data, true_y, train_valid_test: 'str'):\n","  predicted_y = model.predict(data)\n","  accuracy_score = model.score(data, true_y)\n","  f1score = f1_score(true_y, predicted_y, average = 'macro')\n","  \n","\n","  plt.figure(figsize = (4, 4))\n","  sns.set(font_scale=1.2)\n","  cm_result = confusion_matrix(true_y, predicted_y, normalize = 'pred')\n","\n","  confusion_matrix_result_heatmap = sns.heatmap(cm_result, \n","                                                cmap=\"Blues\", \n","                                                annot = True, \n","                                                fmt=\".2f\", annot_kws={'size': 15}, \n","                                                xticklabels=['Negative', 'Positive'], \n","                                                yticklabels=['Negative', 'Positive'])\n","\n","  confusion_matrix_result_heatmap.set(xlabel='Predicted Label', ylabel='True Label', title = 'price movement')\n","\n","  plt.show()\n","  print(f'\\n{train_valid_test} accuracy: {accuracy_score}, {train_valid_test} f1 score: {f1score}')\n","  return accuracy_score, f1score"],"metadata":{"id":"-8ShYoZu-N1s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load Data"],"metadata":{"id":"O0_yDJy6R44J"}},{"cell_type":"markdown","source":["### prepare loughran-mcdonald sentiment dictionary"],"metadata":{"id":"4PSnxwQUASvn"}},{"cell_type":"code","source":["lm_sent_dict = loughran_mcdonald_dict(directory = '../data/TF-IDF Models', \n","                                      file_name = 'Loughran-McDonald_MasterDictionary_1993-2021.csv')"],"metadata":{"id":"dDnU5ckbAX5f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### load 10 folds dataset"],"metadata":{"id":"eD4njH2_72P9"}},{"cell_type":"code","source":["folds_data_path = Path(r'../data/TF-IDF Models/Intermediate Output/dict_folds_data.pickle')\n","\n","if folds_data_path.is_file():\n","  with open(folds_data_path, 'rb') as f_1:\n","    dict_folds_data = pickle.load(f_1)\n","\n","else:\n","  dict_folds_data = prepare_folds_dataset(cv_path = r'../data/TF-IDF Models/Cross Validation_fold_data')"],"metadata":{"id":"dT8nq2l-71PV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### load and split training/ valid dataset"],"metadata":{"id":"TCE1XeUImrpJ"}},{"cell_type":"code","source":["X_train, X_valid, y_train, y_valid = load_dataset(sp500_fn = load_sp500_data, training_data = True)"],"metadata":{"id":"Zmt5jF-qlaFW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Build LinearSVC Pipeline"],"metadata":{"id":"DTLfSx9JSZIw"}},{"cell_type":"markdown","source":["### initialize necessary functions"],"metadata":{"id":"djmOu2a6BDWm"}},{"cell_type":"code","source":["minmaxscaler_price = MinMaxScaler()"],"metadata":{"id":"FLugrZA572n1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### build pipeline (binary label)"],"metadata":{"id":"ij19E1mPVCiy"}},{"cell_type":"code","source":["ma_pipeline = Pipeline(steps = [('norm_price', minmaxscaler_price)])\n","\n","column_transformer = ColumnTransformer(transformers = [('price_ma', ma_pipeline, ['Close', 'MA10', 'MA20', 'MA30',\n","                                                                                  'appl_Close', 'msft_Close', 'amzn_Close', \n","                                                                                  'nvda_Close', 'brk_Close', 'googl_Close', \n","                                                                                  'tsla_Cloae', 'meta_Close', 'xom_Close', 'jpm_Close'])])\n","\n","clf_pipeline_binary = Pipeline(steps = [('preprocessing', column_transformer), \n","                                        ('classification',LinearSVC(C= 0.05, class_weight = 'balanced'))])"],"metadata":{"id":"05mtNKsqQXrc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 10-fold gridsearchcv (Linear SVC)"],"metadata":{"id":"m0jR6Qk53f39"}},{"cell_type":"code","source":["parameters_grid = {'classification__C': [0.001, 0.005, 0.01, 0.05], \n","                   'classification__penalty': ['l2']}\n","\n","parameters = ParameterGrid(parameters_grid)\n","\n","result = gridsearchcv(folds_data = dict_folds_data, parametergrid = parameters, model = clf_pipeline_binary)"],"metadata":{"id":"6z_ZxK0lnPkY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["parameters_grid_1 = {'classification__C': [], 'classification__penalty': []}\n","\n","df_result = pd.DataFrame(result)\n","\n","for parameter in df_result['parameter']:\n","  for key, value in parameter.items():\n","    parameters_grid_1[key].append(value)\n","\n","df_result_1 = df_result.merge(pd.DataFrame(parameters_grid_1), how = 'left', left_index = True, right_index = True)\n","df_result_complete = df_result_1.iloc[:,1:].groupby(['classification__C',\n","                                                     'classification__penalty'], as_index = False).agg({'train_accuracy': ['mean', 'std'], 'train_f1': ['mean', 'std'], 'valid_accuracy': ['mean', 'std'], 'valid_f1': ['mean', 'std']})"],"metadata":{"id":"ENQvpLwwnctz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_result.head()"],"metadata":{"id":"lk19gObEqGWQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_result_complete.iloc[df_result_complete[('valid_f1', 'mean')].idxmax()] # the best combination of parameters "],"metadata":{"id":"b6tvHInloChu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### visualize gridsearchcv result (Linear SVC)"],"metadata":{"id":"aJpYGyeZq6bI"}},{"cell_type":"code","source":["visualize_gridsearchcv(cv_result = df_result_complete)"],"metadata":{"id":"3m-RPmJPrBMd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### confirm the best model (Linear SVC)"],"metadata":{"id":"-bPncZuWqWh9"}},{"cell_type":"code","source":["minmaxscaler_price = MinMaxScaler()\n","\n","ma_pipeline = Pipeline(steps = [('norm_price', minmaxscaler_price)])\n","\n","column_transformer = ColumnTransformer(transformers = [('price_ma', ma_pipeline, ['Close', 'MA10', 'MA20', 'MA30',\n","                                                                                  'appl_Close', 'msft_Close', 'amzn_Close', \n","                                                                                  'nvda_Close', 'brk_Close', 'googl_Close', \n","                                                                                  'tsla_Cloae', 'meta_Close', 'xom_Close', 'jpm_Close'])])\n","\n","clf_pipeline_binary = Pipeline(steps = [('preprocessing', column_transformer), \n","                                        ('classification',LinearSVC(C= 0.05, class_weight = 'balanced'))])\n","\n","clf_pipeline_binary.fit(X_train, y_train['up_down'].values)"],"metadata":{"id":"rqog6itAoJeE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### performance evaluation and confusion matrix (train dataset)"],"metadata":{"id":"LWTpa4aQ5G8G"}},{"cell_type":"code","source":["accuracy_score_train, f1score_train = performance_metrics_binary(model = clf_pipeline_binary, \n","                                                                 data = X_train, \n","                                                                 true_y = y_train['up_down'].values, \n","                                                                 train_valid_test = 'train')"],"metadata":{"id":"jNuZw9zSqzWu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### performance evaluation & confusion matrix (valid dataset)"],"metadata":{"id":"7JzfvzTp5Mb4"}},{"cell_type":"code","source":["accuracy_score_valid, f1score_valid = performance_metrics_binary(model = clf_pipeline_binary, \n","                                                                 data = X_valid, \n","                                                                 true_y = y_valid['up_down'].values, \n","                                                                 train_valid_test = 'valid')"],"metadata":{"id":"4ee_Eg9u15_P"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Build XGBoost Classifier"],"metadata":{"id":"Ymm3jxuk5Wsz"}},{"cell_type":"markdown","source":["### build pipeline"],"metadata":{"id":"h14zEZt0EUzN"}},{"cell_type":"code","source":["minmaxscaler_price_xgboost = MinMaxScaler()\n","ma_pipeline_xg = Pipeline(steps = [('norm_price', minmaxscaler_price_xgboost)])\n","column_transformer_xg = ColumnTransformer(transformers = [('price_ma', ma_pipeline_xg, ['Close', 'MA10', 'MA20', 'MA30',\n","                                                                                        'appl_Close', 'msft_Close', 'amzn_Close', \n","                                                                                        'nvda_Close', 'brk_Close', 'googl_Close', \n","                                                                                        'tsla_Cloae', 'meta_Close', 'xom_Close', 'jpm_Close'])])\n","clf_xgb = XGBClassifier(booster = 'gbtree', tree_method='gpu_hist', min_split_loss = 0.01, learning_rate = 0.01, max_depth = 3, n_estimators = 1000, scale_pos_weight = 0.9)\n","clf_pipeline_binary_xgboost = Pipeline(steps = [('preprocessing', column_transformer_xg), \n","                                                ('classification',clf_xgb)])"],"metadata":{"id":"DLi4Bp202VLU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 10-fold gridsearchcv (XGBoost Classifier)"],"metadata":{"id":"q5Pogu1dEN3W"}},{"cell_type":"code","source":["parameters_grid_xgb = {'classification__learning_rate': [0.0005, 0.0007, 0.001], \n","                   'classification__max_depth': [3, 4 , 5]}\n","\n","parameters_xgb = ParameterGrid(parameters_grid_xgb)\n","\n","result_xgb = gridsearchcv_xgb(folds_data = dict_folds_data, parametergrid = parameters_xgb, model = clf_pipeline_binary_xgboost)"],"metadata":{"id":"b5X50roM6Khk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["parameters_grid_xgb_1 = {'classification__learning_rate': [], 'classification__max_depth': []}\n","\n","df_result_xgb = pd.DataFrame(result_xgb)\n","\n","for parameter in df_result_xgb['parameter']:\n","  for key, value in parameter.items():\n","    parameters_grid_xgb_1[key].append(value)\n","\n","df_result_xgb_1 = df_result_xgb.merge(pd.DataFrame(parameters_grid_xgb_1), how = 'left', left_index = True, right_index = True)\n","df_result_xgb_complete = df_result_xgb_1.iloc[:,1:].groupby(['classification__learning_rate',\n","                                                             'classification__max_depth'], as_index = False).agg({'train_accuracy': ['mean', 'std'], 'train_f1': ['mean', 'std'], 'valid_accuracy': ['mean', 'std'], 'valid_f1': ['mean', 'std']})"],"metadata":{"id":"2BoDXSGM6PxW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_result_xgb_complete.iloc[df_result_xgb_complete[('valid_f1', 'mean')].idxmax()] # the best combination of parameters "],"metadata":{"id":"7PxhIH4TDVb6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_result_xgb_complete"],"metadata":{"id":"nNGyNncwFugE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_cv_result = df_result_xgb_complete[['classification__learning_rate',\n","                            'classification__max_depth',\n","                            'valid_f1']].copy()\n","                               \n","df_cv_result.rename(columns = {'classification__learning_rate': 'learning_rate', \n","                               'classification__max_depth': 'max_depth'}, \n","                      inplace = True)"],"metadata":{"id":"v2qZdlJhDMWL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### visualize gridsearchcv result (XGBoost)"],"metadata":{"id":"6WajjOP4Ef6F"}},{"cell_type":"code","source":["visualize_gridsearchcv_xgb(df_result_xgb_complete)"],"metadata":{"id":"J1xcLbgK92pM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### confirm the best model"],"metadata":{"id":"dvwxsb_PH5Ha"}},{"cell_type":"code","source":["minmaxscaler_price_xgboost = MinMaxScaler()\n","ma_pipeline_xg = Pipeline(steps = [('norm_price', minmaxscaler_price_xgboost)])\n","column_transformer_xg = ColumnTransformer(transformers = [('price_ma', ma_pipeline_xg, ['Close', 'MA10', 'MA20', 'MA30',\n","                                                                                        'appl_Close', 'msft_Close', 'amzn_Close', \n","                                                                                        'nvda_Close', 'brk_Close', 'googl_Close', \n","                                                                                        'tsla_Cloae', 'meta_Close', 'xom_Close', 'jpm_Close'])])\n","clf_xgb = XGBClassifier(booster = 'gbtree', tree_method='gpu_hist', min_split_loss = 0.01, learning_rate = 0.001, max_depth = 4, n_estimators = 1000, scale_pos_weight = 0.9)\n","clf_pipeline_binary_xgboost = Pipeline(steps = [('preprocessing', column_transformer_xg), \n","                                                ('classification',clf_xgb)])\n","\n","clf_pipeline_binary_xgboost.fit(X_train, y_train['up_down'].values)"],"metadata":{"id":"nag3OrCh99hk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### performance evaluation & confusion matrix (train)"],"metadata":{"id":"qsVa4u7ZIW1D"}},{"cell_type":"code","source":["accuracy_score_valid, f1score_valid = performance_metrics_binary(model = clf_pipeline_binary_xgboost, \n","                                                                 data = X_train, \n","                                                                 true_y = y_train['up_down'].values, \n","                                                                 train_valid_test = 'train')"],"metadata":{"id":"oijVUNfTIRRt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### performance evaluation & confusion matrix (valid)"],"metadata":{"id":"D60fFgBiIgoE"}},{"cell_type":"code","source":["accuracy_score_valid, f1score_valid = performance_metrics_binary(model = clf_pipeline_binary_xgboost, \n","                                                                 data = X_valid, \n","                                                                 true_y = y_valid['up_down'].values, \n","                                                                 train_valid_test = 'valid')"],"metadata":{"id":"7-lT5oG2IbYK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Build Stacking Model"],"metadata":{"id":"8-cHEzKOIr5Y"}},{"cell_type":"code","source":["logistic = LogisticRegression()\n","stack_pipeline = StackingClassifier(estimators = [('linearsvc', clf_pipeline_binary), ('xgboost', clf_pipeline_binary_xgboost)], \n","                                    final_estimator = logistic)\n","\n","stack_pipeline.fit(X_train, y_train['up_down'].values)"],"metadata":{"id":"nzn2MZF_IlzP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### performance evaluation & confusion matrix (training data)"],"metadata":{"id":"VjK2ta6EI2_Y"}},{"cell_type":"code","source":["accuracy_score_train, f1score_train = performance_metrics_binary(model = stack_pipeline, \n","                                                                 data = X_train, \n","                                                                 true_y = y_train['up_down'].values, \n","                                                                 train_valid_test = 'train')"],"metadata":{"id":"4phEM4NyIvrf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### performance evaluation & confusion matrix (valid data)"],"metadata":{"id":"v-UkE9twJF05"}},{"cell_type":"code","source":["accuracy_score_valid, f1score_valid = performance_metrics_binary(model = stack_pipeline, \n","                                                                 data = X_valid, \n","                                                                 true_y = y_valid['up_down'].values, \n","                                                                 train_valid_test = 'valid')"],"metadata":{"id":"OMduybXjI655"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 10-fold cross validation (Monte Carlo)"],"metadata":{"id":"H7ptur1u_bYC"}},{"cell_type":"code","source":["folds = ['fold-1', 'fold-2', 'fold-3', 'fold-4', 'fold-5', 'fold-6', 'fold-7', 'fold-8', 'fold-9', 'fold-10']\n","mccv_score_dict = {'fold':[], 'train_accuracy':[], 'train_f1':[], 'valid_accuracy': [], 'valid_f1': []}\n","  \n","for fold in folds:\n","  X_train, y_train = dict_folds_data[fold]['train']\n","  X_valid, y_valid = dict_folds_data[fold]['valid']\n","\n","  minmaxscaler_price = MinMaxScaler()\n","\n","  ma_pipeline = Pipeline(steps = [('norm_price', minmaxscaler_price)])\n","\n","  column_transformer = ColumnTransformer(transformers = [('price_ma', ma_pipeline, ['Close', 'MA10', 'MA20', 'MA30',\n","                                                                                    'appl_Close', 'msft_Close', 'amzn_Close', \n","                                                                                    'nvda_Close', 'brk_Close', 'googl_Close', \n","                                                                                    'tsla_Cloae', 'meta_Close', 'xom_Close', 'jpm_Close'])])\n","\n","  clf_pipeline_binary = Pipeline(steps = [('preprocessing', column_transformer), \n","                                          ('classification',LinearSVC(C= 0.05, class_weight = 'balanced'))])\n","\n","  #-------------------------------------------------------------------------------------------------------------\n","\n","  minmaxscaler_price_xgboost = MinMaxScaler()\n","  ma_pipeline_xg = Pipeline(steps = [('norm_price', minmaxscaler_price_xgboost)])\n","  column_transformer_xg = ColumnTransformer(transformers = [('price_ma', ma_pipeline_xg, ['Close', 'MA10', 'MA20', 'MA30',\n","                                                                                          'appl_Close', 'msft_Close', 'amzn_Close', \n","                                                                                          'nvda_Close', 'brk_Close', 'googl_Close', \n","                                                                                          'tsla_Cloae', 'meta_Close', 'xom_Close', 'jpm_Close'])])\n","  clf_xgb = XGBClassifier(booster = 'gbtree', tree_method='gpu_hist', min_split_loss = 0.01, learning_rate = 0.001, max_depth = 4, n_estimators = 1000, scale_pos_weight = 0.9)\n","  clf_pipeline_binary_xgboost = Pipeline(steps = [('preprocessing', column_transformer_xg), \n","                                                  ('classification',clf_xgb)])\n","  \n","  #--------------------------------------------------------------------------------------------------------------\n","\n","  logistic = LogisticRegression()\n","  stack_pipeline = StackingClassifier(estimators = [('linearsvc', clf_pipeline_binary), ('xgboost', clf_pipeline_binary_xgboost)], \n","                                    final_estimator = logistic)\n","\n","  stack_pipeline.fit(X_train, y_train['up_down'].values)\n","  train_acc = stack_pipeline.score(X_train, y_train['up_down'].values)\n","  predicted_y_train = stack_pipeline.predict(X_train)\n","  train_f1 = f1_score(y_train['up_down'].values, predicted_y_train, average = 'macro')\n","  valid_acc = stack_pipeline.score(X_valid, y_valid['up_down'].values)\n","  predicted_y_valid = stack_pipeline.predict(X_valid)\n","  valid_f1 = f1_score(y_valid['up_down'].values, predicted_y_valid, average = 'macro')\n","\n","  mccv_score_dict['fold'].append(fold)\n","  mccv_score_dict['train_accuracy'].append(train_acc)\n","  mccv_score_dict['train_f1'].append(train_f1)\n","  mccv_score_dict['valid_accuracy'].append(valid_acc)\n","  mccv_score_dict['valid_f1'].append(valid_f1)"],"metadata":{"id":"SbV0hQQiJNsY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_mccv_score_stacking = pd.DataFrame(mccv_score_dict)\n","df_mccv_score_stacking.loc[len(df_mccv_score_stacking)] = ['average', \n","                                                           df_mccv_score_stacking['train_accuracy'].mean(), \n","                                                           df_mccv_score_stacking['train_f1'].mean(), \n","                                                           df_mccv_score_stacking['valid_accuracy'].mean(), \n","                                                           df_mccv_score_stacking['valid_f1'].mean()]\n","\n","df_mccv_score_stacking.loc[len(df_mccv_score_stacking)] = ['std', \n","                                                           df_mccv_score_stacking.iloc[:-1,1].std(), \n","                                                           df_mccv_score_stacking.iloc[:-1,2].std(), \n","                                                           df_mccv_score_stacking.iloc[:-1,3].std(), \n","                                                           df_mccv_score_stacking.iloc[:-1,4].std()]"],"metadata":{"id":"pr3Df_x4BxMF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_mccv_score_stacking"],"metadata":{"id":"24utY3woBy2P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize = (14, 6))\n","ax1 = plt.subplot(2, 2, 1)\n","ax1.plot(df_mccv_score_stacking.iloc[:-2,0], df_mccv_score_stacking.iloc[:-2,1], label = 'train_accuracy', color = 'black', linewidth = 0.5)\n","ax1.axhline(df_mccv_score_stacking.iloc[10, 1], label = 'avg train_accuracy', color = 'black', linewidth = 0.2, linestyle = '--')\n","ax1.set_ylim((0.3, 0.6))\n","ax1.tick_params(labelbottom=False)\n","ax1.legend()\n","ax2 = plt.subplot(2, 2, 3)\n","ax2.plot(df_mccv_score_stacking.iloc[:-2,0], df_mccv_score_stacking.iloc[:-2,3], label = 'valid_accuracy', color = 'black', linewidth = 0.5)\n","ax2.axhline(df_mccv_score_stacking.iloc[10, 3], label = 'avg valid_accuracy', color = 'black', linewidth = 0.2, linestyle = '--')\n","ax2.set_ylim((0.3, 0.6))\n","plt.xticks(rotation = 90)\n","plt.legend()\n","ax3 = plt.subplot(2, 2, 2)\n","ax3.plot(df_mccv_score_stacking.iloc[:-2,0], df_mccv_score_stacking.iloc[:-2,2], label = 'train_f1', color = 'red', linewidth = 0.5)\n","ax3.axhline(df_mccv_score_stacking.iloc[10, 2], label = 'avg train_f1', color = 'red', linewidth = 0.2, linestyle = '--')\n","ax3.set_ylim((0.1, 0.4))\n","ax3.tick_params(labelbottom=False)\n","plt.legend()\n","ax4 = plt.subplot(2, 2, 4)\n","ax4.plot(df_mccv_score_stacking.iloc[:-2,0], df_mccv_score_stacking.iloc[:-2,4], label = 'valid_f1', color = 'red', linewidth = 0.5)\n","ax4.axhline(df_mccv_score_stacking.iloc[10, 4], label = 'avg valid_f1', color = 'red', linewidth = 0.2, linestyle = '--')\n","ax4.set_ylim((0.1, 0.4))\n","plt.xticks(rotation = 90)\n","plt.legend()\n","plt.show()\n"],"metadata":{"id":"M0XDelVzDHEf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Stacking Models : performace evaluation & visualization (train on training & valid dataset and test on test dataset)"],"metadata":{"id":"ytSmH5nrFwKB"}},{"cell_type":"code","source":["X_all_train, X_test, y_all_train, y_test = load_dataset(sp500_fn = load_sp500_data, training_data = False)\n"],"metadata":{"id":"q-ARX2J9FAUR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mccv_score_dict_all = {'train_accuracy':[], 'train_f1':[], 'test_accuracy': [], 'test_f1': []}\n","\n","minmaxscaler_price = MinMaxScaler()\n","\n","ma_pipeline = Pipeline(steps = [('norm_price', minmaxscaler_price)])\n","\n","column_transformer = ColumnTransformer(transformers = [('price_ma', ma_pipeline, ['Close', 'MA10', 'MA20', 'MA30',\n","                                                                                  'appl_Close', 'msft_Close', 'amzn_Close', \n","                                                                                  'nvda_Close', 'brk_Close', 'googl_Close', \n","                                                                                  'tsla_Cloae', 'meta_Close', 'xom_Close', 'jpm_Close'])])\n","\n","clf_pipeline_binary = Pipeline(steps = [('preprocessing', column_transformer), \n","                                        ('classification',LinearSVC(C= 0.05, class_weight = 'balanced'))])\n","\n","#-------------------------------------------------------------------------------------------------------------\n","\n","minmaxscaler_price_xgboost = MinMaxScaler()\n","ma_pipeline_xg = Pipeline(steps = [('norm_price', minmaxscaler_price_xgboost)])\n","column_transformer_xg = ColumnTransformer(transformers = [('price_ma', ma_pipeline_xg, ['Close', 'MA10', 'MA20', 'MA30',\n","                                                                                        'appl_Close', 'msft_Close', 'amzn_Close', \n","                                                                                        'nvda_Close', 'brk_Close', 'googl_Close', \n","                                                                                        'tsla_Cloae', 'meta_Close', 'xom_Close', 'jpm_Close'])])\n","clf_xgb = XGBClassifier(booster = 'gbtree', tree_method='gpu_hist', min_split_loss = 0.01, learning_rate = 0.001, max_depth = 4, n_estimators = 1000, scale_pos_weight = 0.9)\n","clf_pipeline_binary_xgboost = Pipeline(steps = [('preprocessing', column_transformer_xg), \n","                                                ('classification',clf_xgb)])\n","\n","#--------------------------------------------------------------------------------------------------------------\n","\n","logistic = LogisticRegression()\n","stack_pipeline = StackingClassifier(estimators = [('linearsvc', clf_pipeline_binary), ('xgboost', clf_pipeline_binary_xgboost)], \n","                                  final_estimator = logistic)\n","\n","stack_pipeline.fit(X_all_train, y_all_train['up_down'].values)\n","train_all_acc = stack_pipeline.score(X_all_train, y_all_train['up_down'].values)\n","predicted_y_all_train = stack_pipeline.predict(X_all_train)\n","train_all_f1 = f1_score(y_all_train['up_down'].values, predicted_y_all_train, average = 'macro')\n","test_acc = stack_pipeline.score(X_test, y_test['up_down'].values)\n","predicted_y_test = stack_pipeline.predict(X_test)\n","test_f1 = f1_score(y_test['up_down'].values, predicted_y_test, average = 'macro')\n","\n","mccv_score_dict_all['train_accuracy'].append(train_all_acc)\n","mccv_score_dict_all['train_f1'].append(train_all_f1)\n","mccv_score_dict_all['test_accuracy'].append(test_acc)\n","mccv_score_dict_all['test_f1'].append(test_f1)"],"metadata":{"id":"yORjw7RSF0ei"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pd.DataFrame(mccv_score_dict_all)"],"metadata":{"id":"e0N1OgElLGKZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### performance evaluation & confusion matrix (train & valid)"],"metadata":{"id":"oIS45ohbOETI"}},{"cell_type":"code","source":["accuracy_score_valid, f1score_valid = performance_metrics_binary(model = stack_pipeline, \n","                                                                 data = X_all_train, \n","                                                                 true_y = y_all_train['up_down'].values, \n","                                                                 train_valid_test = 'train_valid')"],"metadata":{"id":"KGPYz_kHNO_r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### performance evalution & confusion matrix (test)"],"metadata":{"id":"Uod60Q_1OJid"}},{"cell_type":"code","source":["accuracy_score_valid, f1score_valid = performance_metrics_binary(model = stack_pipeline, \n","                                                                 data = X_test, \n","                                                                 true_y = y_test['up_down'].values, \n","                                                                 train_valid_test = 'test')"],"metadata":{"id":"UxKuY1OgNzXr"},"execution_count":null,"outputs":[]}]}